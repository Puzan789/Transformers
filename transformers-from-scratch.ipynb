{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:36:35.069545Z","iopub.execute_input":"2024-02-03T04:36:35.070240Z","iopub.status.idle":"2024-02-03T04:36:47.392818Z","shell.execute_reply.started":"2024-02-03T04:36:35.070208Z","shell.execute_reply":"2024-02-03T04:36:47.391816Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-02-03 04:36:37.086692: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-03 04:36:37.086787: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-03 04:36:37.211184: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\nInside each attention head is a **Scaled Dot Product Self-Attention** operation as we covered in the slides. Given *queries*, *keys*, and *values*, the operation returns a new \"mix\" of the values.\n\n$$Attention(Q, K, V) = softmax(\\frac{QK^T)}{\\sqrt{d_k}})V$$\n\nThe following function implements this and also takes a mask to account for padding and for masking future tokens for decoding (i.e. **look-ahead mask**). We'll cover masking later in the notebook.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Example sentence\nsentence = \"ChatGPT is a powerful language model developed by OpenAI.\"\n\n# Tokenize the sentence (for simplicity, splitting by whitespace)\ntokens = sentence.split()\n\n# Embedding dimension\nembed_dim = 4\n\n# Generate random word embeddings for query, keys, and values\nquery = np.random.rand(len(tokens), embed_dim)\nkeys = np.random.rand(len(tokens), embed_dim)\nvalues = np.random.rand(len(tokens), embed_dim)\n\nprint(\"Tokens:\", tokens)\nprint(\"\\nQuery (representing what we want to focus on):\\n\", query)\nprint(\"\\nKeys (used to compute attention scores):\\n\", keys)\nprint(\"\\nValues (actual content to be weighted by attention):\\n\", values)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:36:47.394660Z","iopub.execute_input":"2024-02-03T04:36:47.395782Z","iopub.status.idle":"2024-02-03T04:36:47.404035Z","shell.execute_reply.started":"2024-02-03T04:36:47.395743Z","shell.execute_reply":"2024-02-03T04:36:47.403171Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Tokens: ['ChatGPT', 'is', 'a', 'powerful', 'language', 'model', 'developed', 'by', 'OpenAI.']\n\nQuery (representing what we want to focus on):\n [[0.46847462 0.55728415 0.05759386 0.50289439]\n [0.88920322 0.53325944 0.93581348 0.22094825]\n [0.31026488 0.10372769 0.39506193 0.73457544]\n [0.69338079 0.22518227 0.44290632 0.94135132]\n [0.46429722 0.59473349 0.72871288 0.5137612 ]\n [0.24564315 0.7080508  0.89020335 0.11812936]\n [0.89369661 0.45697618 0.31179819 0.57846279]\n [0.48877444 0.86706101 0.42218196 0.71727902]\n [0.5987527  0.7469727  0.72846239 0.41204846]]\n\nKeys (used to compute attention scores):\n [[0.48701525 0.14010646 0.20521205 0.81737574]\n [0.33358357 0.6259162  0.51800412 0.69906038]\n [0.59493203 0.05543959 0.06590504 0.97363518]\n [0.38382367 0.54254271 0.73150523 0.8711893 ]\n [0.36934798 0.30439262 0.8468169  0.92941526]\n [0.55704418 0.99395462 0.30430115 0.32216649]\n [0.41118298 0.52651466 0.01441199 0.09073061]\n [0.90034636 0.10263335 0.90043922 0.55586274]\n [0.46346165 0.15850118 0.90953575 0.29830747]]\n\nValues (actual content to be weighted by attention):\n [[0.73667309 0.60480567 0.96152532 0.46196874]\n [0.76395323 0.47178206 0.02621785 0.14498663]\n [0.76988825 0.34962947 0.91473124 0.57888761]\n [0.00568095 0.63306378 0.37774753 0.11037174]\n [0.33299241 0.98721246 0.63604541 0.40942573]\n [0.0421496  0.01330122 0.68534409 0.2737992 ]\n [0.31237862 0.58298337 0.35872448 0.20147247]\n [0.00846602 0.65186062 0.40453597 0.50194082]\n [0.15614744 0.02568685 0.02075355 0.77554012]]\n","output_type":"stream"}]},{"cell_type":"code","source":"def scaled_dot_product_attention(query,key,values,mask=None):\n    \n    key_dim=tf.cast(tf.shape(key)[-1], tf.float32)\n    scaled_scores= tf.matmul(query,key,transpose_b=True) / np.sqrt (key_dim)\n    if mask is not None:\n        scaled_scores = tf.where(mask==0, -np.inf, scaled_scores)\n    \n    softmax=tf.keras.layers.Softmax()\n    weights=softmax(scaled_scores)\n    return tf.matmul(weights,values),weights\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:36:52.166053Z","iopub.execute_input":"2024-02-03T04:36:52.166856Z","iopub.status.idle":"2024-02-03T04:36:52.172593Z","shell.execute_reply.started":"2024-02-03T04:36:52.166828Z","shell.execute_reply":"2024-02-03T04:36:52.171705Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"seq_len=3\nembed_dim=4\nqueries=np.random.rand(seq_len,embed_dim)\nkeys=np.random.rand(seq_len,embed_dim)\nvalues=np.random.rand(seq_len,embed_dim)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:36:55.456965Z","iopub.execute_input":"2024-02-03T04:36:55.457800Z","iopub.status.idle":"2024-02-03T04:36:55.462312Z","shell.execute_reply.started":"2024-02-03T04:36:55.457766Z","shell.execute_reply":"2024-02-03T04:36:55.461413Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"output, attn_weights = scaled_dot_product_attention(queries, keys, values)\n\nprint(\"Output\\n\", output, \"\\n\")\nprint(\"Weights\\n\", attn_weights)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:03.980157Z","iopub.execute_input":"2024-02-03T04:37:03.980490Z","iopub.status.idle":"2024-02-03T04:37:03.992251Z","shell.execute_reply.started":"2024-02-03T04:37:03.980464Z","shell.execute_reply":"2024-02-03T04:37:03.991233Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Output\n tf.Tensor(\n[[0.4759968  0.35926855 0.5374737  0.59249526]\n [0.46812192 0.36584187 0.53658634 0.5869098 ]\n [0.46033582 0.36937323 0.5173398  0.5811532 ]], shape=(3, 4), dtype=float32) \n\nWeights\n tf.Tensor(\n[[0.34181294 0.37451047 0.28367662]\n [0.33770812 0.38685325 0.27543864]\n [0.3794669  0.37407982 0.24645327]], shape=(3, 3), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## multi head Self attention","metadata":{}},{"cell_type":"code","source":"batch_size = 1\nseq_len = 3\nembed_dim = 12\nnum_heads = 3 # eti times chai Q K V calculate hunxa\nhead_dim = embed_dim // num_heads\n\nprint(f\"Dimension of each head: {head_dim}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:06.189561Z","iopub.execute_input":"2024-02-03T04:37:06.189920Z","iopub.status.idle":"2024-02-03T04:37:06.195392Z","shell.execute_reply.started":"2024-02-03T04:37:06.189891Z","shell.execute_reply":"2024-02-03T04:37:06.194367Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Dimension of each head: 4\n","output_type":"stream"}]},{"cell_type":"code","source":"x = np.random.rand(batch_size, seq_len, embed_dim).round(1) # round(1) bhaneko round up gareko\nprint(\"Input shape: \", x.shape, \"\\n\")\nprint(\"Input:\\n\", x)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:08.371564Z","iopub.execute_input":"2024-02-03T04:37:08.372288Z","iopub.status.idle":"2024-02-03T04:37:08.377897Z","shell.execute_reply.started":"2024-02-03T04:37:08.372255Z","shell.execute_reply":"2024-02-03T04:37:08.376871Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Input shape:  (1, 3, 12) \n\nInput:\n [[[0.6 0.8 0.2 0.6 0.6 0.8 0.6 0.4 0.4 0.5 0.8 1. ]\n  [0.8 0.4 0.9 0.8 0.5 0.6 0.5 0.3 0.3 0.5 0.4 0.4]\n  [0.8 0.  0.9 0.7 0.  0.2 0.3 0.3 0.7 0.4 0.4 1. ]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# query weights for each head\nwq0=np.random.rand(embed_dim,head_dim).round(1)\nwq1=np.random.rand(embed_dim,head_dim).round(1)\nwq2=np.random.rand(embed_dim,head_dim).round(1)\n\n# key weights for each head\nwk0=np.random.rand(embed_dim,head_dim).round(1)\nwk1=np.random.rand(embed_dim,head_dim).round(1)\nwk2=np.random.rand(embed_dim,head_dim).round(1)\n\n# value weights for each head\nwv0=np.random.rand(embed_dim,head_dim).round(1)\nwv1=np.random.rand(embed_dim,head_dim).round(1)\nwv2=np.random.rand(embed_dim,head_dim).round(1)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:10.699037Z","iopub.execute_input":"2024-02-03T04:37:10.699724Z","iopub.status.idle":"2024-02-03T04:37:10.706816Z","shell.execute_reply.started":"2024-02-03T04:37:10.699694Z","shell.execute_reply":"2024-02-03T04:37:10.705880Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(\"wq0:\\n\",wq0)\nprint(\"wq1:\\n\",wq1)\nprint(\"wq2:\\n\",wq2)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:13.521102Z","iopub.execute_input":"2024-02-03T04:37:13.521904Z","iopub.status.idle":"2024-02-03T04:37:13.528621Z","shell.execute_reply.started":"2024-02-03T04:37:13.521869Z","shell.execute_reply":"2024-02-03T04:37:13.527596Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"wq0:\n [[0.8 0.5 0.5 0.9]\n [0.2 0.2 0.7 0.7]\n [0.2 0.3 0.3 0.6]\n [0.6 0.  0.5 0.8]\n [0.8 0.6 0.6 0.4]\n [0.5 0.3 0.7 0.4]\n [0.6 0.1 0.8 1. ]\n [0.2 0.9 0.7 0.4]\n [0.3 0.1 0.2 0. ]\n [0.9 0.6 0.7 0.2]\n [0.  0.3 0.8 0.8]\n [0.5 0.5 0.3 0.9]]\nwq1:\n [[0.3 0.8 0.1 0.7]\n [0.4 0.5 0.7 0.3]\n [0.7 0.7 0.1 0.1]\n [0.1 0.3 1.  0.5]\n [0.5 0.4 0.6 0.8]\n [1.  0.1 0.5 0.3]\n [0.2 0.3 0.5 0.2]\n [0.  1.  0.  0.4]\n [0.3 0.4 0.1 0.5]\n [0.2 0.8 0.6 0.3]\n [0.3 0.1 0.7 0.9]\n [0.9 0.3 0.4 0.4]]\nwq2:\n [[0.7 0.3 1.  0.2]\n [0.4 0.1 0.7 0.9]\n [0.8 0.3 0.6 0.2]\n [0.  0.7 0.1 0.2]\n [0.5 0.8 0.  0.1]\n [0.5 0.5 1.  0.3]\n [0.6 0.5 0.3 0. ]\n [0.8 0.7 0.1 0.9]\n [0.3 0.7 0.3 0.5]\n [0.6 0.3 0.7 0.7]\n [0.3 1.  0.6 0.2]\n [0.4 0.6 0.2 0.2]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Generating queries keys and values for 3 heads","metadata":{}},{"cell_type":"code","source":"q0=np.dot(x,wq0)\nk0=np.dot(x,wk0)\nv0=np.dot(x,wv0)\n\nq1=np.dot(x,wq1)\nk1=np.dot(x,wk1)\nv1=np.dot(x,wv1)\n\nq2=np.dot(x,wq2)\nk2=np.dot(x,wk2)\nv2=np.dot(x,wv2)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:18.711558Z","iopub.execute_input":"2024-02-03T04:37:18.712135Z","iopub.status.idle":"2024-02-03T04:37:18.718201Z","shell.execute_reply.started":"2024-02-03T04:37:18.712104Z","shell.execute_reply":"2024-02-03T04:37:18.717150Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"q0.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-02T08:20:45.147081Z","iopub.execute_input":"2024-02-02T08:20:45.147355Z","iopub.status.idle":"2024-02-02T08:20:45.159225Z","shell.execute_reply.started":"2024-02-02T08:20:45.147332Z","shell.execute_reply":"2024-02-02T08:20:45.158381Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(1, 3, 4)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Now we pass them to self attention operation","metadata":{}},{"cell_type":"code","source":"out0,attn_weights0=scaled_dot_product_attention(q0,k0,v0)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:22.428037Z","iopub.execute_input":"2024-02-03T04:37:22.428700Z","iopub.status.idle":"2024-02-03T04:37:22.439532Z","shell.execute_reply.started":"2024-02-03T04:37:22.428668Z","shell.execute_reply":"2024-02-03T04:37:22.438656Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"out1,_=scaled_dot_product_attention(q1,k1,v1)\nout2,_=scaled_dot_product_attention(q1,k1,v1)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:24.844120Z","iopub.execute_input":"2024-02-03T04:37:24.844738Z","iopub.status.idle":"2024-02-03T04:37:24.857644Z","shell.execute_reply.started":"2024-02-03T04:37:24.844708Z","shell.execute_reply":"2024-02-03T04:37:24.856828Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"combined_out_a=np.concatenate((out0,out1,out2),axis=-1)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:27.163318Z","iopub.execute_input":"2024-02-03T04:37:27.163675Z","iopub.status.idle":"2024-02-03T04:37:27.168603Z","shell.execute_reply.started":"2024-02-03T04:37:27.163647Z","shell.execute_reply":"2024-02-03T04:37:27.167646Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"combined_out_a.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:30.466651Z","iopub.execute_input":"2024-02-03T04:37:30.467032Z","iopub.status.idle":"2024-02-03T04:37:30.473691Z","shell.execute_reply.started":"2024-02-03T04:37:30.467003Z","shell.execute_reply":"2024-02-03T04:37:30.472708Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(1, 3, 12)"},"metadata":{}}]},{"cell_type":"code","source":"combined_out_a","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:33.106541Z","iopub.execute_input":"2024-02-03T04:37:33.107450Z","iopub.status.idle":"2024-02-03T04:37:33.113641Z","shell.execute_reply.started":"2024-02-03T04:37:33.107414Z","shell.execute_reply":"2024-02-03T04:37:33.112740Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([[[3.342269 , 4.4451604, 3.4119306, 3.6446478, 2.7585423,\n         3.8347876, 3.3595817, 3.9946008, 2.7585423, 3.8347876,\n         3.3595817, 3.9946008],\n        [3.330148 , 4.4309726, 3.4041188, 3.6375225, 2.728777 ,\n         3.8075252, 3.357984 , 3.9665766, 2.728777 , 3.8075252,\n         3.357984 , 3.9665766],\n        [3.3049078, 4.4025617, 3.3879461, 3.6222346, 2.701246 ,\n         3.780736 , 3.3554769, 3.938585 , 2.701246 , 3.780736 ,\n         3.3554769, 3.938585 ]]], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Lets perform this by using a single query matrix,singlekeyweightmatrix and single value weight matrix","metadata":{}},{"cell_type":"code","source":"wq0","metadata":{"execution":{"iopub.status.busy":"2024-02-02T08:20:45.216304Z","iopub.execute_input":"2024-02-02T08:20:45.216591Z","iopub.status.idle":"2024-02-02T08:20:45.227036Z","shell.execute_reply.started":"2024-02-02T08:20:45.216569Z","shell.execute_reply":"2024-02-02T08:20:45.226208Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array([[0. , 0.9, 0.8, 0.1],\n       [1. , 0.6, 0.1, 0.8],\n       [0.1, 0.4, 0.2, 0.4],\n       [0.1, 0.3, 0.9, 0.5],\n       [0.9, 0.7, 0.7, 0.3],\n       [0.3, 0.3, 0.2, 0.2],\n       [0.4, 0. , 0.5, 0.8],\n       [1. , 0. , 0.3, 0.7],\n       [0.9, 0.8, 0.5, 0.4],\n       [0.6, 0.8, 1. , 1. ],\n       [0.9, 0.6, 0.4, 0.9],\n       [0.3, 0.6, 0.3, 0.1]])"},"metadata":{}}]},{"cell_type":"code","source":"wq=np.concatenate((wq0,wq1,wq2),axis=1)\nwk=np.concatenate((wk0,wk1,wk2),axis=1)\nwv=np.concatenate((wv0,wv1,wv2),axis=1)\n\nwv.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:36.377525Z","iopub.execute_input":"2024-02-03T04:37:36.378169Z","iopub.status.idle":"2024-02-03T04:37:36.386892Z","shell.execute_reply.started":"2024-02-03T04:37:36.378136Z","shell.execute_reply":"2024-02-03T04:37:36.386015Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(12, 12)"},"metadata":{}}]},{"cell_type":"code","source":"q_s=np.dot(x,wq)\nk_s=np.dot(x,wk)\nv_s=np.dot(x,wv)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:38.471932Z","iopub.execute_input":"2024-02-03T04:37:38.472295Z","iopub.status.idle":"2024-02-03T04:37:38.477171Z","shell.execute_reply.started":"2024-02-03T04:37:38.472268Z","shell.execute_reply":"2024-02-03T04:37:38.476148Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"k_s.shape # 1 bhaneko batch size 3 bhaneko sequence length 12 bhaneko embed_dim\n","metadata":{"execution":{"iopub.status.busy":"2024-02-02T08:20:45.247886Z","iopub.execute_input":"2024-02-02T08:20:45.248443Z","iopub.status.idle":"2024-02-02T08:20:45.258880Z","shell.execute_reply.started":"2024-02-02T08:20:45.248412Z","shell.execute_reply":"2024-02-02T08:20:45.258224Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(1, 3, 12)"},"metadata":{}}]},{"cell_type":"code","source":"qs_reshaped=tf.reshape(q_s,(batch_size,seq_len,num_heads,head_dim))\nks_reshaped=tf.reshape(k_s,(batch_size,seq_len,num_heads,head_dim))\nvs_reshaped=tf.reshape(v_s,(batch_size,seq_len,num_heads,head_dim))","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:40.888755Z","iopub.execute_input":"2024-02-03T04:37:40.889103Z","iopub.status.idle":"2024-02-03T04:37:40.897495Z","shell.execute_reply.started":"2024-02-03T04:37:40.889078Z","shell.execute_reply":"2024-02-03T04:37:40.896679Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"print(qs_reshaped)\nprint(ks_reshaped)\nprint(vs_reshaped)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:42.781614Z","iopub.execute_input":"2024-02-03T04:37:42.781995Z","iopub.status.idle":"2024-02-03T04:37:42.789391Z","shell.execute_reply.started":"2024-02-03T04:37:42.781956Z","shell.execute_reply":"2024-02-03T04:37:42.788431Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"tf.Tensor(\n[[[[3.43 2.62 4.27 4.66]\n   [3.28 3.04 3.6  3.45]\n   [3.34 4.03 3.51 2.57]]\n\n  [[3.18 2.2  3.53 4.02]\n   [2.73 3.1  2.87 2.79]\n   [3.2  3.27 3.24 2.02]]\n\n  [[2.65 1.96 2.65 3.62]\n   [2.51 2.83 2.11 2.47]\n   [2.77 3.07 2.66 1.72]]]], shape=(1, 3, 3, 4), dtype=float64)\ntf.Tensor(\n[[[[3.98 2.06 3.29 2.76]\n   [3.89 2.78 4.17 3.38]\n   [2.94 3.6  3.54 4.09]]\n\n  [[3.42 2.2  2.7  2.56]\n   [3.15 2.68 3.85 2.71]\n   [2.99 3.57 3.34 3.74]]\n\n  [[3.01 1.89 1.9  2.43]\n   [2.44 2.88 3.12 2.65]\n   [2.2  2.84 2.72 3.83]]]], shape=(1, 3, 3, 4), dtype=float64)\ntf.Tensor(\n[[[[3.37 4.48 3.43 3.66]\n   [2.8  3.87 3.36 4.03]\n   [2.71 3.76 4.2  3.31]]\n\n  [[3.05 4.06 3.22 3.49]\n   [1.9  3.15 3.38 3.32]\n   [2.09 3.89 3.94 2.76]]\n\n  [[2.29 3.53 2.76 2.9 ]\n   [2.18 2.91 3.07 2.93]\n   [2.07 3.64 2.87 2.52]]]], shape=(1, 3, 3, 4), dtype=float64)\n","output_type":"stream"}]},{"cell_type":"code","source":"qs_transposed=tf.transpose(qs_reshaped,perm=[0,2,1,3]).numpy()\nks_transposed = tf.transpose(ks_reshaped, perm=[0, 2, 1, 3]).numpy()\nvs_transposed = tf.transpose(vs_reshaped, perm=[0, 2, 1, 3]).numpy()\nprint(f\"Keys for all heads in a single matrix {ks_transposed.shape}: \\n\", ks_transposed, \"\\n\")\nprint(f\"Values for all heads in a single matrix {v_s.shape}: \\n\", vs_transposed)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:45.810124Z","iopub.execute_input":"2024-02-03T04:37:45.810487Z","iopub.status.idle":"2024-02-03T04:37:45.828273Z","shell.execute_reply.started":"2024-02-03T04:37:45.810458Z","shell.execute_reply":"2024-02-03T04:37:45.827204Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Keys for all heads in a single matrix (1, 3, 3, 4): \n [[[[3.98 2.06 3.29 2.76]\n   [3.42 2.2  2.7  2.56]\n   [3.01 1.89 1.9  2.43]]\n\n  [[3.89 2.78 4.17 3.38]\n   [3.15 2.68 3.85 2.71]\n   [2.44 2.88 3.12 2.65]]\n\n  [[2.94 3.6  3.54 4.09]\n   [2.99 3.57 3.34 3.74]\n   [2.2  2.84 2.72 3.83]]]] \n\nValues for all heads in a single matrix (1, 3, 12): \n [[[[3.37 4.48 3.43 3.66]\n   [3.05 4.06 3.22 3.49]\n   [2.29 3.53 2.76 2.9 ]]\n\n  [[2.8  3.87 3.36 4.03]\n   [1.9  3.15 3.38 3.32]\n   [2.18 2.91 3.07 2.93]]\n\n  [[2.71 3.76 4.2  3.31]\n   [2.09 3.89 3.94 2.76]\n   [2.07 3.64 2.87 2.52]]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"all_heads_output, all_attn_weights = scaled_dot_product_attention(qs_transposed, \n                                                                  ks_transposed, \n                                                                  vs_transposed)\nprint(\"Self attention output:\\n\", all_heads_output)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:49.072090Z","iopub.execute_input":"2024-02-03T04:37:49.072433Z","iopub.status.idle":"2024-02-03T04:37:49.085889Z","shell.execute_reply.started":"2024-02-03T04:37:49.072406Z","shell.execute_reply":"2024-02-03T04:37:49.084988Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Self attention output:\n tf.Tensor(\n[[[[3.342269  4.4451604 3.4119306 3.6446478]\n   [3.330148  4.4309726 3.4041188 3.6375225]\n   [3.3049078 4.4025617 3.3879461 3.6222346]]\n\n  [[2.7585423 3.8347876 3.3595817 3.9946008]\n   [2.728777  3.8075252 3.357984  3.9665766]\n   [2.701246  3.780736  3.3554769 3.938585 ]]\n\n  [[2.5115862 3.7997582 4.1090894 3.1323748]\n   [2.4918818 3.8027678 4.0961404 3.113914 ]\n   [2.4745855 3.8046224 4.081486  3.097021 ]]]], shape=(1, 3, 3, 4), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"combined_out_b = tf.reshape(tf.transpose(all_heads_output, perm=[0, 2, 1, 3]), \n                            shape=(batch_size, seq_len, embed_dim))\nprint(\"Final output from using single query, key, value matrices:\\n\", \n      combined_out_b, \"\\n\")\nprint(\"Final output from using separate query, key, value matrices per head:\\n\", \n      combined_out_a)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:52.553250Z","iopub.execute_input":"2024-02-03T04:37:52.553614Z","iopub.status.idle":"2024-02-03T04:37:52.564991Z","shell.execute_reply.started":"2024-02-03T04:37:52.553585Z","shell.execute_reply":"2024-02-03T04:37:52.564155Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Final output from using single query, key, value matrices:\n tf.Tensor(\n[[[3.342269  4.4451604 3.4119306 3.6446478 2.7585423 3.8347876 3.3595817\n   3.9946008 2.5115862 3.7997582 4.1090894 3.1323748]\n  [3.330148  4.4309726 3.4041188 3.6375225 2.728777  3.8075252 3.357984\n   3.9665766 2.4918818 3.8027678 4.0961404 3.113914 ]\n  [3.3049078 4.4025617 3.3879461 3.6222346 2.701246  3.780736  3.3554769\n   3.938585  2.4745855 3.8046224 4.081486  3.097021 ]]], shape=(1, 3, 12), dtype=float32) \n\nFinal output from using separate query, key, value matrices per head:\n [[[3.342269  4.4451604 3.4119306 3.6446478 2.7585423 3.8347876 3.3595817\n   3.9946008 2.7585423 3.8347876 3.3595817 3.9946008]\n  [3.330148  4.4309726 3.4041188 3.6375225 2.728777  3.8075252 3.357984\n   3.9665766 2.728777  3.8075252 3.357984  3.9665766]\n  [3.3049078 4.4025617 3.3879461 3.6222346 2.701246  3.780736  3.3554769\n   3.938585  2.701246  3.780736  3.3554769 3.938585 ]]]\n","output_type":"stream"}]},{"cell_type":"code","source":"class MultiHeadSelfAttention(tf.keras.layers.Layer):\n  def __init__(self, d_model, num_heads):\n    super(MultiHeadSelfAttention, self).__init__()\n    self.d_model = d_model\n    self.num_heads = num_heads\n\n    self.d_head = self.d_model // self.num_heads\n\n    self.wq = tf.keras.layers.Dense(self.d_model)\n    self.wk = tf.keras.layers.Dense(self.d_model)\n    self.wv = tf.keras.layers.Dense(self.d_model)\n\n    # Linear layer to generate the final output.\n    self.dense = tf.keras.layers.Dense(self.d_model)\n  \n  def split_heads(self, x):\n    batch_size = x.shape[0]\n\n    split_inputs = tf.reshape(x, (batch_size, -1, self.num_heads, self.d_head))\n    return tf.transpose(split_inputs, perm=[0, 2, 1, 3])\n  \n  def merge_heads(self, x):\n    batch_size = x.shape[0]\n\n    merged_inputs = tf.transpose(x, perm=[0, 2, 1, 3])\n    return tf.reshape(merged_inputs, (batch_size, -1, self.d_model))\n\n  def call(self, q, k, v, mask):\n    qs = self.wq(q)\n    ks = self.wk(k)\n    vs = self.wv(v)\n    qs = self.split_heads(qs)\n    ks = self.split_heads(ks)\n    vs = self.split_heads(vs)\n\n    output, attn_weights = scaled_dot_product_attention(qs, ks, vs, mask)\n    output = self.merge_heads(output)\n\n    return self.dense(output), attn_weights\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:37:54.615852Z","iopub.execute_input":"2024-02-03T04:37:54.616225Z","iopub.status.idle":"2024-02-03T04:37:54.628259Z","shell.execute_reply.started":"2024-02-03T04:37:54.616197Z","shell.execute_reply":"2024-02-03T04:37:54.627267Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"mhsa = MultiHeadSelfAttention(12, 3)\n\noutput, attn_weights = mhsa(x, x, x, None)\nprint(f\"MHSA output{output.shape}:\")\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:38:01.530405Z","iopub.execute_input":"2024-02-03T04:38:01.531066Z","iopub.status.idle":"2024-02-03T04:38:01.619090Z","shell.execute_reply.started":"2024-02-03T04:38:01.531035Z","shell.execute_reply":"2024-02-03T04:38:01.618220Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"MHSA output(1, 3, 12):\ntf.Tensor(\n[[[-0.14611931 -0.00353573 -0.33451563 -0.12995589 -0.14621437\n   -0.17226407  0.46141407  0.33941475  0.25833526 -0.8124912\n    0.12275562 -0.5625761 ]\n  [-0.15156002 -0.00864987 -0.3424868  -0.11953118 -0.1656064\n   -0.16633493  0.47230232  0.32969716  0.26439598 -0.805861\n    0.13228002 -0.56805676]\n  [-0.14889887 -0.00572135 -0.35030594 -0.14110234 -0.16682968\n   -0.1949113   0.4835528   0.35853136  0.26331925 -0.79940844\n    0.10877711 -0.58139986]]], shape=(1, 3, 12), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"def multi_head_attention(num_heads,embed_dim,mask=None):\n    d_head=embed_dim//num_heads\n    wq=tf.keras.layers.Dense(embed_dim)\n    wk=tf.keras.layers.Dense(embed_dim)\n    wv=tf.keras.layers.Dense(embed_dim)\n    dense=tf.keras.layers.Dense(embed_dim)\n    \n    qs=wq(embed_dim)\n    ks=wk(embed_dim)\n    vs=wv(embed_dim)\n    \n    def split_heads(x,d_head):\n        batch_size=x.shape[0]\n        split_inputs=tf.reshape(x,(batch_size,-1,num_heads,d_head))\n        return tf.transpose(split_inputs,perms=[0,2,1,3])\n    def merge_heads(x):\n\n        batch_size = x.shape[0]\n        merged_inputs = tf.transpose(x, perm=[0, 2, 1, 3])\n        \n        return tf.reshape(merged_inputs, (batch_size, -1, d_model))\n    qs=split_heads(qs,d_head)\n    ks=split_heads(ks,d_head)    \n    vs=split_heads(vs,d_head)    \n    \n    output, attn_weights = scaled_dot_product_attention(qs, ks, vs, mask)\n    output = merge_heads(output)\n    return dense(output),attn_weights","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:38:04.493710Z","iopub.execute_input":"2024-02-03T04:38:04.494086Z","iopub.status.idle":"2024-02-03T04:38:04.504080Z","shell.execute_reply.started":"2024-02-03T04:38:04.494057Z","shell.execute_reply":"2024-02-03T04:38:04.503005Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def multiheads(q,k,v,embed_dims,num_heads,mask=None):\n    d_heads=embed_dims//num_heads\n    wq=tf.keras.layers.Dense(embed_dims)\n    wk=tf.keras.layers.Dense(embed_dims)\n    wv=tf.keras.layers.Dense(embed_dims)\n    dense=tf.keras.layers.Dense(embed_dims)\n    qs=wq(embed_dims)\n    ks=wk(embed_dims)\n    vs=wv(embed_dims)\n    def split_heads(x,d_heads):\n        batch_size=x.shape[0]\n        split_inputs=tf.reshape(x,(batch_size,-1,num_heads,d_head))\n        return tf.transpose(split_inputs,perms=[0,2,1,3])\n    def merge_heads(x,d_heads):\n        batch_size=x.shape[0]\n        merged_inputs = tf.reshape(x, perm=[0, 2, 1, 3])\n        return tf.reshape(merged_inputs, (batch_size, -1, d_model))\n    qs=split_heads(qs,d_heads)\n    ks=split_heads(ks,d_heads)    \n    vs=split_heads(vs,d_heads)    \n    output,attn_weights=scaled_dot_product_attention(qs,ks,vs)\n    return dense(output),attn_weights","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:38:07.292927Z","iopub.execute_input":"2024-02-03T04:38:07.293759Z","iopub.status.idle":"2024-02-03T04:38:07.302389Z","shell.execute_reply.started":"2024-02-03T04:38:07.293726Z","shell.execute_reply":"2024-02-03T04:38:07.301491Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def multiheads(embed_dims, num_heads, mask=None):\n    d_heads = embed_dims // num_heads\n\n    wq = tf.keras.layers.Dense(embed_dims)\n    wk = tf.keras.layers.Dense(embed_dims)\n    wv = tf.keras.layers.Dense(embed_dims)\n    dense = tf.keras.layers.Dense(embed_dims)\n\n    qs = wq(embed_dims)\n    ks = wk(embed_dims)\n    vs = wv(embed_dims)\n\n    def split_heads(x, d_heads):\n        batch_size = tf.shape(x)[0]\n        split_inputs = tf.reshape(x, (batch_size, -1, num_heads, d_heads))\n        return tf.transpose(split_inputs, perm=[0, 2, 1, 3])\n\n    def merge_heads(x, d_heads):\n        batch_size = tf.shape(x)[0]\n        merged_inputs = tf.reshape(x, (batch_size, -1, embed_dims))\n        return merged_inputs\n\n    qs = split_heads(qs, d_heads)\n    ks = split_heads(ks, d_heads)\n    vs = split_heads(vs, d_heads)\n\n    output, attn_weights = scaled_dot_product_attention(qs, ks, vs, mask)\n\n    output = merge_heads(output, d_heads)\n    output = dense(output)\n\n    return output, attn_weights","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:38:08.848938Z","iopub.execute_input":"2024-02-03T04:38:08.849606Z","iopub.status.idle":"2024-02-03T04:38:08.858325Z","shell.execute_reply.started":"2024-02-03T04:38:08.849574Z","shell.execute_reply":"2024-02-03T04:38:08.857324Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mhsa = MultiHeadSelfAttention(12, 3)\n\noutput, attn_weights = mhsa(x, x, x, None)\nprint(f\"MHSA output{output.shape}:\")\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:42:13.206460Z","iopub.execute_input":"2024-02-03T04:42:13.207318Z","iopub.status.idle":"2024-02-03T04:42:13.257622Z","shell.execute_reply.started":"2024-02-03T04:42:13.207289Z","shell.execute_reply":"2024-02-03T04:42:13.255745Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"MHSA output(1, 3, 12):\ntf.Tensor(\n[[[-0.5498718   0.06832296 -0.00361164 -0.5559154  -0.18834695\n   -0.18672106 -0.2933884  -0.35499278  0.8286581   0.5925399\n   -0.5859465  -0.21757594]\n  [-0.54551506  0.05759305 -0.00373295 -0.5550678  -0.18249266\n   -0.17363487 -0.28998953 -0.35304824  0.82220197  0.5951256\n   -0.5906154  -0.22028092]\n  [-0.54178023  0.06347764 -0.00188243 -0.5565109  -0.17512456\n   -0.17662172 -0.29091316 -0.35038674  0.8201754   0.592192\n   -0.58951706 -0.21935263]]], shape=(1, 3, 12), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"def feed_forward_network(d_model, hidden_dim):\n  return tf.keras.Sequential([\n      tf.keras.layers.Dense(hidden_dim, activation='relu'),\n      tf.keras.layers.Dense(d_model)\n  ])","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:42:15.725374Z","iopub.execute_input":"2024-02-03T04:42:15.725711Z","iopub.status.idle":"2024-02-03T04:42:15.730704Z","shell.execute_reply.started":"2024-02-03T04:42:15.725686Z","shell.execute_reply":"2024-02-03T04:42:15.729699Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class EncoderBlock(tf.keras.layers.Layer):\n  def __init__(self, d_model, num_heads, hidden_dim, dropout_rate=0.1):\n    super(EncoderBlock, self).__init__()\n\n    self.mhsa = MultiHeadSelfAttention(d_model, num_heads)\n    self.ffn = feed_forward_network(d_model, hidden_dim)\n\n    self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n    self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n\n    self.layernorm1 = tf.keras.layers.LayerNormalization()\n    self.layernorm2 = tf.keras.layers.LayerNormalization()\n  \n  def call(self, x, training, mask):\n    mhsa_output, attn_weights = self.mhsa(x, x, x, mask)\n    mhsa_output = self.dropout1(mhsa_output, training=training)\n    mhsa_output = self.layernorm1(x + mhsa_output)\n\n    ffn_output = self.ffn(mhsa_output)\n    ffn_output = self.dropout2(ffn_output, training=training)\n    output = self.layernorm2(mhsa_output + ffn_output)\n\n    return output, attn_weights\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:49:29.896863Z","iopub.execute_input":"2024-02-03T04:49:29.897602Z","iopub.status.idle":"2024-02-03T04:49:29.905424Z","shell.execute_reply.started":"2024-02-03T04:49:29.897573Z","shell.execute_reply":"2024-02-03T04:49:29.904467Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"!pip install BPEmb\nfrom bpemb import BPEmb\n# Load the English tokenizer.\nbpemb_en = BPEmb(lang=\"en\")","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:56:16.322058Z","iopub.execute_input":"2024-02-03T04:56:16.322435Z","iopub.status.idle":"2024-02-03T04:56:47.890346Z","shell.execute_reply.started":"2024-02-03T04:56:16.322397Z","shell.execute_reply":"2024-02-03T04:56:47.889534Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Requirement already satisfied: BPEmb in /opt/conda/lib/python3.10/site-packages (0.3.4)\nRequirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (from BPEmb) (4.3.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from BPEmb) (1.24.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from BPEmb) (2.31.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from BPEmb) (0.1.99)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from BPEmb) (4.66.1)\nRequirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim->BPEmb) (1.11.4)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim->BPEmb) (6.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->BPEmb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->BPEmb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->BPEmb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->BPEmb) (2023.11.17)\ndownloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 400869/400869 [00:00<00:00, 706676.81B/s]\n","output_type":"stream"},{"name":"stdout","text":"downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.d100.w2v.bin.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3784656/3784656 [00:01<00:00, 3673708.24B/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"sample_sentence = \"Where can I find a pizzeria?\"\ntokens = bpemb_en.encode(sample_sentence)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:58:51.345648Z","iopub.execute_input":"2024-02-03T04:58:51.346595Z","iopub.status.idle":"2024-02-03T04:58:51.351776Z","shell.execute_reply.started":"2024-02-03T04:58:51.346551Z","shell.execute_reply":"2024-02-03T04:58:51.350874Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"['▁where', '▁can', '▁i', '▁find', '▁a', '▁p', 'iz', 'zer', 'ia', '?']\n","output_type":"stream"}]},{"cell_type":"code","source":"token_seq = np.array(bpemb_en.encode_ids(\"Where can I find a pizzeria?\"))\nprint(token_seq)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T04:59:05.255543Z","iopub.execute_input":"2024-02-03T04:59:05.256576Z","iopub.status.idle":"2024-02-03T04:59:05.263519Z","shell.execute_reply.started":"2024-02-03T04:59:05.256529Z","shell.execute_reply":"2024-02-03T04:59:05.262297Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"[ 571  280  386 1934    4   24  248 4339  177 9967]\n","output_type":"stream"}]},{"cell_type":"code","source":"bpemb_vocab_size, bpemb_embed_size = bpemb_en.vectors.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:01:35.524039Z","iopub.execute_input":"2024-02-03T05:01:35.524417Z","iopub.status.idle":"2024-02-03T05:01:35.528801Z","shell.execute_reply.started":"2024-02-03T05:01:35.524383Z","shell.execute_reply":"2024-02-03T05:01:35.527898Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"token_embed = tf.keras.layers.Embedding(bpemb_vocab_size, embed_dim)\ntoken_embeddings = token_embed(token_seq)\n\n# The untrained embeddings for our sample sentence.\nprint(\"Embeddings for: \", sample_sentence)\nprint(token_embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:02:47.227224Z","iopub.execute_input":"2024-02-03T05:02:47.227878Z","iopub.status.idle":"2024-02-03T05:02:47.240903Z","shell.execute_reply.started":"2024-02-03T05:02:47.227845Z","shell.execute_reply":"2024-02-03T05:02:47.240008Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Embeddings for:  Where can I find a pizzeria?\ntf.Tensor(\n[[-0.02258208  0.01114035 -0.03177005  0.03801126 -0.03929411 -0.03286447\n  -0.00218701  0.00356279 -0.03534804 -0.02564455 -0.04835266 -0.01086277]\n [ 0.01455561 -0.04867085 -0.00847696 -0.02035747 -0.040521    0.03266202\n   0.0439996   0.03630202 -0.04357444 -0.0140309  -0.02653326  0.04436481]\n [-0.03320471  0.01401706  0.01552368 -0.02872876 -0.01238068  0.00583403\n   0.0386689  -0.04964479 -0.03199156 -0.02197343  0.0231226   0.04751891]\n [-0.03421488 -0.04697162  0.01468997  0.03280308 -0.0119614  -0.00092625\n   0.02728098 -0.02973909 -0.0060048  -0.03663726 -0.00198963 -0.04671491]\n [ 0.02037365  0.02644915  0.01711626 -0.00621597  0.00655352 -0.03800426\n  -0.00190554 -0.02403221  0.00326009 -0.00012296  0.01326806  0.00483131]\n [ 0.0389953   0.04068813  0.0178881  -0.01872829  0.02109568 -0.03778852\n   0.00726242  0.02649016  0.0428809  -0.04017204  0.04011536 -0.00675756]\n [ 0.03222758  0.04906735 -0.03853768 -0.01601539 -0.03127895 -0.00722932\n   0.02706634  0.01367046  0.02065915  0.02679839 -0.03658136 -0.02265772]\n [ 0.01206691 -0.04857598 -0.02362748  0.0451459  -0.0251654  -0.01332032\n   0.01312851  0.03374246 -0.0225529  -0.00111408 -0.03989469  0.0030242 ]\n [ 0.0159852  -0.03749191  0.04503609  0.00782452  0.03528457 -0.0190774\n   0.01671919 -0.00662915 -0.02645025  0.04245645 -0.00342663 -0.02037543]\n [-0.00614665 -0.00744427  0.01270957 -0.02690097 -0.04310037 -0.00216953\n  -0.04917109  0.0014186  -0.0015443   0.04114026  0.04295201  0.00387549]], shape=(10, 12), dtype=float32)\n","output_type":"stream"}]},{"cell_type":"code","source":"bpemb_vocab_size","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:02:22.230125Z","iopub.execute_input":"2024-02-03T05:02:22.230940Z","iopub.status.idle":"2024-02-03T05:02:22.238800Z","shell.execute_reply.started":"2024-02-03T05:02:22.230898Z","shell.execute_reply":"2024-02-03T05:02:22.237726Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"10000"},"metadata":{}}]},{"cell_type":"code","source":"embed_dim","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:03:08.417507Z","iopub.execute_input":"2024-02-03T05:03:08.418169Z","iopub.status.idle":"2024-02-03T05:03:08.423641Z","shell.execute_reply.started":"2024-02-03T05:03:08.418135Z","shell.execute_reply":"2024-02-03T05:03:08.422775Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"12"},"metadata":{}}]},{"cell_type":"code","source":"class Encoder(tf.keras.layers.Layer):\n  def __init__(self, num_blocks, d_model, num_heads, hidden_dim, src_vocab_size,\n               max_seq_len, dropout_rate=0.1):\n    super(Encoder, self).__init__()\n\n    self.d_model = d_model\n    self.max_seq_len = max_seq_len\n\n    self.token_embed = tf.keras.layers.Embedding(src_vocab_size, self.d_model)\n    self.pos_embed = tf.keras.layers.Embedding(max_seq_len, self.d_model)\n\n    # The original Attention Is All You Need paper applied dropout to the\n    # input before feeding it to the first encoder block.\n    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n\n    # Create encoder blocks.\n    self.blocks = [EncoderBlock(self.d_model, num_heads, hidden_dim, dropout_rate) \n    for _ in range(num_blocks)]\n  \n  def calld(self, input, training, mask):\n    token_embeds = self.token_embed(input)\n\n    # Generate position indices for a batch of input sequences.\n    num_pos = input.shape[0] * self.max_seq_len\n    pos_idx = np.resize(np.arange(self.max_seq_len), num_pos)\n    pos_idx = np.reshape(pos_idx, input.shape)\n    pos_embeds = self.pos_embed(pos_idx)\n\n    x = self.dropout(token_embeds + pos_embeds, training=training)\n\n    # Run input through successive encoder blocks.\n    for block in self.blocks:\n      x, weights = block(x, training, mask)\n\n    return x, weights","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:14:28.327695Z","iopub.execute_input":"2024-02-03T05:14:28.328429Z","iopub.status.idle":"2024-02-03T05:14:28.338537Z","shell.execute_reply.started":"2024-02-03T05:14:28.328394Z","shell.execute_reply":"2024-02-03T05:14:28.337440Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"class DecoderBlock(tf.keras.layers.Layer):\n  def __init__(self, d_model, num_heads, hidden_dim, dropout_rate=0.1):\n    super(DecoderBlock, self).__init__()\n\n    self.mhsa1 = MultiHeadSelfAttention(d_model, num_heads)\n    self.mhsa2 = MultiHeadSelfAttention(d_model, num_heads)\n\n    self.ffn = feed_forward_network(d_model, hidden_dim)\n\n    self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n    self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n    self.dropout3 = tf.keras.layers.Dropout(dropout_rate)\n\n    self.layernorm1 = tf.keras.layers.LayerNormalization()\n    self.layernorm2 = tf.keras.layers.LayerNormalization()\n    self.layernorm3 = tf.keras.layers.LayerNormalization()\n  \n  # Note the decoder block takes two masks. One for the first MHSA, another\n  # for the second MHSA.\n  def call(self, encoder_output, target, training, decoder_mask, memory_mask):\n    mhsa_output1, attn_weights = self.mhsa1(target, target, target, decoder_mask)\n    mhsa_output1 = self.dropout1(mhsa_output1, training=training)\n    mhsa_output1 = self.layernorm1(mhsa_output1 + target)\n\n    mhsa_output2, attn_weights = self.mhsa2(mhsa_output1, encoder_output, \n                                            encoder_output, \n                                            memory_mask)\n    mhsa_output2 = self.dropout2(mhsa_output2, training=training)\n    mhsa_output2 = self.layernorm2(mhsa_output2 + mhsa_output1)\n\n    ffn_output = self.ffn(mhsa_output2)\n    ffn_output = self.dropout3(ffn_output, training=training)\n    output = self.layernorm3(ffn_output + mhsa_output2)\n\n    return output, attn_weights\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:15:09.537494Z","iopub.execute_input":"2024-02-03T05:15:09.538214Z","iopub.status.idle":"2024-02-03T05:15:09.548772Z","shell.execute_reply.started":"2024-02-03T05:15:09.538184Z","shell.execute_reply":"2024-02-03T05:15:09.547666Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class Decoder(tf.keras.layers.Layer):\n  def __init__(self, num_blocks, d_model, num_heads, hidden_dim, target_vocab_size,\n               max_seq_len, dropout_rate=0.1):\n    super(Decoder, self).__init__()\n\n    self.d_model = d_model\n    self.max_seq_len = max_seq_len\n\n    self.token_embed = tf.keras.layers.Embedding(target_vocab_size, self.d_model)\n    self.pos_embed = tf.keras.layers.Embedding(max_seq_len, self.d_model)\n\n    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n\n    self.blocks = [DecoderBlock(self.d_model, num_heads, hidden_dim, dropout_rate) for _ in range(num_blocks)]\n\n  def call(self, encoder_output, target, training, decoder_mask, memory_mask):\n    token_embeds = self.token_embed(target)\n\n    # Generate position indices.\n    num_pos = target.shape[0] * self.max_seq_len\n    pos_idx = np.resize(np.arange(self.max_seq_len), num_pos)\n    pos_idx = np.reshape(pos_idx, target.shape)\n\n    pos_embeds = self.pos_embed(pos_idx)\n\n    x = self.dropout(token_embeds + pos_embeds, training=training)\n\n    for block in self.blocks:\n      x, weights = block(encoder_output, x, training, decoder_mask, memory_mask)\n\n    return x, weights","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:15:32.473663Z","iopub.execute_input":"2024-02-03T05:15:32.474392Z","iopub.status.idle":"2024-02-03T05:15:32.484230Z","shell.execute_reply.started":"2024-02-03T05:15:32.474346Z","shell.execute_reply":"2024-02-03T05:15:32.483320Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"class Transformer(tf.keras.Model):\n  def __init__(self, num_blocks, d_model, num_heads, hidden_dim, source_vocab_size,\n               target_vocab_size, max_input_len, max_target_len, dropout_rate=0.1):\n    super(Transformer, self).__init__()\n\n    self.encoder = Encoder(num_blocks, d_model, num_heads, hidden_dim, source_vocab_size, \n                           max_input_len, dropout_rate)\n    \n    self.decoder = Decoder(num_blocks, d_model, num_heads, hidden_dim, target_vocab_size,\n                           max_target_len, dropout_rate)\n    \n    # The final dense layer to generate logits from the decoder output.\n    self.output_layer = tf.keras.layers.Dense(target_vocab_size)\n\n  def call(self, input_seqs, target_input_seqs, training, encoder_mask,\n           decoder_mask, memory_mask):\n    encoder_output, encoder_attn_weights = self.encoder(input_seqs, \n                                                        training, encoder_mask)\n\n    decoder_output, decoder_attn_weights = self.decoder(encoder_output, \n                                                        target_input_seqs, training,\n                                                        decoder_mask, memory_mask)\n\n    return self.output_layer(decoder_output), encoder_attn_weights, decoder_attn_weights\n","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:16:21.029464Z","iopub.execute_input":"2024-02-03T05:16:21.029834Z","iopub.status.idle":"2024-02-03T05:16:21.037767Z","shell.execute_reply.started":"2024-02-03T05:16:21.029806Z","shell.execute_reply":"2024-02-03T05:16:21.036771Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"input_batch = [\n    \"Where can I find a pizzeria?\",\n    \"Mass hysteria over listeria.\",\n    \"I ain't no circle back girl.\"\n]\n\nbpemb_en.encode(input_batch)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:17:54.418740Z","iopub.execute_input":"2024-02-03T05:17:54.419680Z","iopub.status.idle":"2024-02-03T05:17:54.426267Z","shell.execute_reply.started":"2024-02-03T05:17:54.419646Z","shell.execute_reply":"2024-02-03T05:17:54.425431Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"[['▁where', '▁can', '▁i', '▁find', '▁a', '▁p', 'iz', 'zer', 'ia', '?'],\n ['▁mass', '▁hy', 'ster', 'ia', '▁over', '▁l', 'ister', 'ia', '.'],\n ['▁i', '▁a', 'in', \"'\", 't', '▁no', '▁circle', '▁back', '▁girl', '.']]"},"metadata":{}}]},{"cell_type":"code","source":"input_seqs = bpemb_en.encode_ids(input_batch)\nprint(\"Vectorized inputs:\")\ninput_seqs","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:17:57.138564Z","iopub.execute_input":"2024-02-03T05:17:57.138926Z","iopub.status.idle":"2024-02-03T05:17:57.146801Z","shell.execute_reply.started":"2024-02-03T05:17:57.138897Z","shell.execute_reply":"2024-02-03T05:17:57.145763Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Vectorized inputs:\n","output_type":"stream"},{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"[[571, 280, 386, 1934, 4, 24, 248, 4339, 177, 9967],\n [1535, 1354, 1238, 177, 380, 43, 871, 177, 9935],\n [386, 4, 6, 9937, 9915, 467, 5410, 810, 3692, 9935]]"},"metadata":{}}]},{"cell_type":"code","source":"\npadded_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(input_seqs, padding=\"post\")\nprint(\"Input to the encoder:\")\nprint(padded_input_seqs.shape)\nprint(padded_input_seqs)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:18:00.380562Z","iopub.execute_input":"2024-02-03T05:18:00.381284Z","iopub.status.idle":"2024-02-03T05:18:00.387362Z","shell.execute_reply.started":"2024-02-03T05:18:00.381247Z","shell.execute_reply":"2024-02-03T05:18:00.386461Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Input to the encoder:\n(3, 10)\n[[ 571  280  386 1934    4   24  248 4339  177 9967]\n [1535 1354 1238  177  380   43  871  177 9935    0]\n [ 386    4    6 9937 9915  467 5410  810 3692 9935]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Made up values.\ntarget_input_seqs = [\n    [1, 652, 723, 123, 62],\n    [1, 25,  98, 129, 248, 215, 359, 249],\n    [1, 2369, 1259, 125, 486],\n]\npadded_target_input_seqs = tf.keras.preprocessing.sequence.pad_sequences(target_input_seqs, padding=\"post\")\nprint(\"Padded target inputs to the decoder:\")\nprint(padded_target_input_seqs.shape)\nprint(padded_target_input_seqs)","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:19:26.875045Z","iopub.execute_input":"2024-02-03T05:19:26.875673Z","iopub.status.idle":"2024-02-03T05:19:26.882591Z","shell.execute_reply.started":"2024-02-03T05:19:26.875645Z","shell.execute_reply":"2024-02-03T05:19:26.881647Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Padded target inputs to the decoder:\n(3, 8)\n[[   1  652  723  123   62    0    0    0]\n [   1   25   98  129  248  215  359  249]\n [   1 2369 1259  125  486    0    0    0]]\n","output_type":"stream"}]},{"cell_type":"code","source":"transformer = Transformer(\n    num_blocks = 6,\n    d_model = 12,\n    num_heads = 3,\n    hidden_dim = 48,\n    source_vocab_size = bpemb_vocab_size,\n    target_vocab_size = 7000, # made-up target vocab size.\n    max_input_len = padded_input_seqs.shape[1],\n    max_target_len = padded_target_input_seqs.shape[1])\n\ntransformer_output, _, _ = transformer(padded_input_seqs, \n                                       padded_target_input_seqs, True, \n                                       enc_mask, dec_mask, memory_mask=enc_mask)\nprint(f\"Transformer output {transformer_output.shape}:\")\nprint(transformer_output) # If training, we would use this output to calculate losses.","metadata":{"execution":{"iopub.status.busy":"2024-02-03T05:19:30.013059Z","iopub.execute_input":"2024-02-03T05:19:30.013419Z","iopub.status.idle":"2024-02-03T05:19:30.265614Z","shell.execute_reply.started":"2024-02-03T05:19:30.013391Z","shell.execute_reply":"2024-02-03T05:19:30.264463Z"},"trusted":true},"execution_count":68,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[68], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m transformer \u001b[38;5;241m=\u001b[39m Transformer(\n\u001b[1;32m      2\u001b[0m     num_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m      3\u001b[0m     d_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     max_input_len \u001b[38;5;241m=\u001b[39m padded_input_seqs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      9\u001b[0m     max_target_len \u001b[38;5;241m=\u001b[39m padded_target_input_seqs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     11\u001b[0m transformer_output, _, _ \u001b[38;5;241m=\u001b[39m transformer(padded_input_seqs, \n\u001b[1;32m     12\u001b[0m                                        padded_target_input_seqs, \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m---> 13\u001b[0m                                        \u001b[43menc_mask\u001b[49m, dec_mask, memory_mask\u001b[38;5;241m=\u001b[39menc_mask)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer output \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformer_output\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(transformer_output) \u001b[38;5;66;03m# If training, we would use this output to calculate losses.\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'enc_mask' is not defined"],"ename":"NameError","evalue":"name 'enc_mask' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}